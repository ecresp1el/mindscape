#!/usr/bin/env python
# NOTE: This script is located in tools/create_workflow_scaffold.py and is intended for developer use.
import os
import re
from pathlib import Path
import argparse
import yaml

from mindscape.bioinformatics_workflow_engine.utils.logger import setup_logger
from mindscape.bioinformatics_workflow_engine.utils.validation import warn_if_missing_from_config
from mindscape.bioinformatics_workflow_engine.utils.dynamic_imports import dynamic_import_workflows

# TEMPLATE_HEADER is now a format string that includes the runner_name dynamically.
# This allows the generated file to have a header that reflects its own filename,
# improving clarity for users.
TEMPLATE_HEADER = '''"""
Workflow Runner Script: {runner_name}

This script was automatically generated by the developer tool:
  mindscape/tools/generate_workflow_runner.py

Purpose:
- Custom workflow execution with dynamic registration of workflow classes.
- Includes only BaseWorkflow by default.
- Does NOT pre-import hardcoded subclasses.
- Dynamically loads workflows defined in the config.yaml (via dynamic_import_workflows).
- Useful for users who want to bootstrap custom workflow runners programmatically.

Location:
- Generated inside the MindScape repository under:
  mindscape/bioinformatics_workflow_engine/

Usage:
- Run this script similarly to run_workflows.py:
  python {runner_name} --project_path /path/to/project

Dynamic Workflow Registration:
- Place your workflow subclasses inside mindscape/bioinformatics_workflow_engine/pipelines/
- Ensure they inherit from BaseWorkflow
- Ensure their class name matches the name listed in config.yaml under workflows -> name
- This script will scan and register only enabled workflows

Example config snippet:
workflows:
  - name: MyNewWorkflow
    enabled: true

This supports modular pipeline development and simplifies developer onboarding.
"""'''

IMPORTS_BLOCK = """
import os
import re
from pathlib import Path
import argparse
import yaml

from mindscape.bioinformatics_workflow_engine.pipelines.base_workflow import BaseWorkflow
from mindscape.bioinformatics_workflow_engine.utils.logger import setup_logger
from mindscape.bioinformatics_workflow_engine.utils.validation import warn_if_missing_from_config
from mindscape.bioinformatics_workflow_engine.utils.dynamic_imports import dynamic_import_workflows
"""

WORKFLOW_MANAGER_CLASS = '''

class WorkflowManager:
    def __init__(self, config_path, project_path):
        self.config_path = config_path
        self.project_path = project_path
        self.config = self.load_config()
        pipeline_dir = Path(__file__).parent / "pipelines"
        self.available_workflows = dynamic_import_workflows(pipeline_dir)
        configured_names = {wf["name"] for wf in self.config.get("workflows", [])}
        warn_if_missing_from_config(pipeline_dir, configured_names)
        self.logger = setup_logger("workflow_manager", "workflow_manager.log")
        self.workflows = []

    def load_config(self):
        with open(self.config_path, 'r') as file:
            return yaml.safe_load(file)

    def register_workflows(self):
        workflow_order = self.config.get("workflows", [])
        for workflow in workflow_order:
            workflow_name = workflow.get("name")
            if workflow.get("enabled", False):
                workflow_class = self.available_workflows.get(workflow_name)
                if workflow_class and hasattr(workflow_class, "run") and workflow_class.run != BaseWorkflow.run:
                    self.workflows.append(workflow_class(config_path=self.config_path, logger=self.logger))
                else:
                    self.logger.warning(f"Workflow {workflow_name} not found or not implemented.")

    def run_workflows(self):
        force_rerun = self.config.get("force_rerun", False)
        for workflow in self.workflows:
            workflow_name = workflow.__class__.__name__
            self.logger.info(f"Running workflow: {workflow_name}")
            if not force_rerun:
                if hasattr(workflow, "is_already_completed") and workflow.is_already_completed():
                    self.logger.info(f"✅ Skipping {workflow_name}: already completed.")
                    continue
            try:
                workflow.run()
                if hasattr(workflow, "mark_completed"):
                    workflow.mark_completed()
                self.logger.info(f"✅ Workflow {workflow_name} completed successfully.")
            except RuntimeError as e:
                self.logger.error(f"❌ Failed to run workflow {workflow_name}: {e}")
'''

MAIN_BLOCK = '''
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run Bioinformatics Workflows")
    parser.add_argument("--project_path", type=str, required=True, help="Path to the MindScape project")
    args = parser.parse_args()

    project_path = Path(args.project_path)
    config_path = project_path / "config/config.yaml"
    if not config_path.exists():
        raise FileNotFoundError(f"Configuration file not found at {config_path}")

    logger = setup_logger("workflow_manager", "workflow_manager.log", log_dir=project_path / "logs")
    workflow_manager = WorkflowManager(config_path=config_path, project_path=project_path)
    workflow_manager.register_workflows()
    workflow_manager.run_workflows()
'''

def main():
    logger = setup_logger("generate_runner", "generate_runner.log")
    parser = argparse.ArgumentParser(description="Generate a blank run_workflows.py template")
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="Output file name for the generated workflow runner (default: run_workflows_template.py)"
    )
    args, _ = parser.parse_known_args()

    if args.output is None:
        project_name = os.environ.get("MINDSCAPE_PROJECT_NAME", "custom_workflow_runner")
        sanitized = re.sub(r'\W+', '_', project_name.lower())
        args.output = str(Path(__file__).resolve().parent.parent / "bioinformatics_workflow_engine" / f"run_workflows_{sanitized}.py")

    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # Extract the runner script name for use in the header
    runner_name = output_path.name

    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w") as f:
        f.write(TEMPLATE_HEADER.format(runner_name=runner_name) + "\n")
        f.write(IMPORTS_BLOCK + "\n")
        f.write(WORKFLOW_MANAGER_CLASS + "\n")
        f.write(MAIN_BLOCK)

    logger.info(f"✅ Template '{runner_name}' created at {output_path}. You can now add your workflows to it.")
    logger.debug(f"Output path exists = {output_path.exists()}")
    logger.debug(f"Output parent directory = {output_path.parent}")


if __name__ == "__main__":
    main()

def generate_runner_template(output_path):
    """
    External function to generate a blank workflow runner script at the given path.
    Used by testscript_cli.py when --blank_runner is provided.
    """
    logger = setup_logger("generate_runner", "generate_runner.log")
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # Extract the runner script name for use in the header
    runner_name = output_path.name

    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w") as f:
        f.write(TEMPLATE_HEADER.format(runner_name=runner_name) + "\n")
        f.write(IMPORTS_BLOCK + "\n")
        f.write(WORKFLOW_MANAGER_CLASS + "\n")
        f.write(MAIN_BLOCK)
    logger.info(f"✅ Template '{runner_name}' created at {output_path}. You can now add your workflows to it.")